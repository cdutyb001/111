#!/usr/bin/env python3
"""
SGSNet ONNXå¯¼å‡ºè„šæœ¬ - ç®€åŒ–ç‰ˆ

ä½¿ç”¨æ–¹æ³•:
    # å¯¼å‡ºæ ‡å‡†æ¨¡å‹ (éšæœºåˆå§‹åŒ–)
    python3 export_sgsnet_onnx.py
    
    # å¯¼å‡ºè½»é‡çº§æ¨¡å‹
    python3 export_sgsnet_onnx.py --model-size lite
    
    # å¯¼å‡ºå¤§å‹æ¨¡å‹
    python3 export_sgsnet_onnx.py --model-size large
    
    # æŒ‡å®šè¾“å‡ºè·¯å¾„å’Œåˆ†è¾¨ç‡
    python3 export_sgsnet_onnx.py --output models/sgsnet.onnx --height 480 --width 640
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡
    python3 export_sgsnet_onnx.py --weights checkpoints/sgsnet.pth
"""

import torch
import torch.onnx
import argparse
import os
import sys

# å¯¼å…¥SGSNetæ¨¡å‹
from sgsnet import SGSNet, SGSNetLite, SGSNetLarge


def export_onnx(
    weights_path: str = None,
    output_path: str = "models/sgsnet.onnx",
    height: int = 480,
    width: int = 640,
    model_size: str = 'standard',
    max_depth: float = 100.0,
    opset_version: int = 13
):
    """å¯¼å‡ºSGSNetä¸ºONNXæ ¼å¼"""
    
    print("=" * 60)
    print("SGSNet ONNX Export")
    print("=" * 60)
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = os.path.dirname(output_path)
    if output_dir:
        os.makedirs(output_dir, exist_ok=True)
    
    # ========== 1. åˆ›å»ºæ¨¡å‹ ==========
    print(f"\n[1/5] Creating {model_size} model...")
    
    if model_size == 'lite':
        model = SGSNetLite(max_depth=max_depth)
    elif model_size == 'large':
        model = SGSNetLarge(max_depth=max_depth)
    else:
        model = SGSNet(base_channels=32, max_depth=max_depth)
    
    # åŠ è½½é¢„è®­ç»ƒæƒé‡ (å¦‚æœæä¾›)
    if weights_path and os.path.exists(weights_path):
        print(f"      Loading weights from: {weights_path}")
        state_dict = torch.load(weights_path, map_location='cpu')
        model.load_state_dict(state_dict)
        print("      âœ“ Weights loaded successfully")
    else:
        print("      Using randomly initialized weights")
    
    model.eval()
    print(f"\n{model.get_memory_footprint()}")
    
    # ========== 2. é€‰æ‹©è®¾å¤‡ ==========
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    print(f"\n[2/5] Using device: {device}")
    model = model.to(device)
    
    # ========== 3. åˆ›å»ºç¤ºä¾‹è¾“å…¥ ==========
    print(f"\n[3/5] Creating dummy inputs ({height}x{width})...")
    dummy_rgb = torch.randn(1, 3, height, width, device=device)
    dummy_sparse_depth = torch.randn(1, 1, height, width, device=device).abs() * 20
    dummy_sparse_depth[dummy_sparse_depth < 10] = 0  # æ¨¡æ‹Ÿç¨€ç–æ·±åº¦
    
    # æµ‹è¯•å‰å‘ä¼ æ’­
    with torch.no_grad():
        dense_depth, uncertainty = model(dummy_rgb, dummy_sparse_depth)
    print(f"      Output dense_depth shape: {dense_depth.shape}")
    print(f"      Output uncertainty shape: {uncertainty.shape}")
    
    # ========== 4. å¯¼å‡ºONNX ==========
    print(f"\n[4/5] Exporting to ONNX (opset {opset_version})...")
    
    # åŠ¨æ€è½´é…ç½®
    dynamic_axes = {
        'rgb': {0: 'batch', 2: 'height', 3: 'width'},
        'sparse_depth': {0: 'batch', 2: 'height', 3: 'width'},
        'dense_depth': {0: 'batch', 2: 'height', 3: 'width'},
        'uncertainty': {0: 'batch', 2: 'height', 3: 'width'}
    }
    
    torch.onnx.export(
        model,
        (dummy_rgb, dummy_sparse_depth),
        output_path,
        input_names=['rgb', 'sparse_depth'],
        output_names=['dense_depth', 'uncertainty'],
        dynamic_axes=dynamic_axes,
        opset_version=opset_version,
        do_constant_folding=True,
        export_params=True,
        verbose=False
    )
    
    file_size_mb = os.path.getsize(output_path) / (1024 * 1024)
    print(f"      âœ“ Exported to: {output_path}")
    print(f"      File size: {file_size_mb:.2f} MB")
    
    # ========== 5. éªŒè¯ONNXæ¨¡å‹ ==========
    print("\n[5/5] Validating ONNX model...")
    try:
        import onnx
        onnx_model = onnx.load(output_path)
        onnx.checker.check_model(onnx_model)
        print("      âœ“ ONNX model validation passed!")
    except ImportError:
        print("      âš  onnx package not installed, skipping validation")
        print("      Install with: pip install onnx")
    except Exception as e:
        print(f"      âœ— Validation failed: {e}")
        return False
    
    # ========== å®Œæˆ ==========
    print("\n" + "=" * 60)
    print("âœ“ Export completed successfully!")
    print("=" * 60)
    
    # æ‰“å°ä½¿ç”¨æç¤º
    print("\nğŸ“Œ Usage in C++:")
    print(f"   // Load with ONNX Runtime or TensorRT")
    print(f"   // Input: rgb (1,3,{height},{width}), sparse_depth (1,1,{height},{width})")
    print(f"   // Output: dense_depth (1,1,{height},{width}), uncertainty (1,1,{height},{width})")
    
    print("\nğŸ“Œ TensorRT conversion:")
    print(f"   trtexec --onnx={output_path} \\")
    print(f"           --saveEngine={output_path.replace('.onnx', '.trt')} \\")
    print(f"           --fp16")
    
    return True


def main():
    parser = argparse.ArgumentParser(
        description='Export SGSNet to ONNX format',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  python3 export_sgsnet_onnx.py                          # å¯¼å‡ºæ ‡å‡†æ¨¡å‹
  python3 export_sgsnet_onnx.py --model-size lite        # å¯¼å‡ºè½»é‡çº§æ¨¡å‹
  python3 export_sgsnet_onnx.py --weights model.pth      # ä½¿ç”¨é¢„è®­ç»ƒæƒé‡
  python3 export_sgsnet_onnx.py --height 240 --width 320 # æŒ‡å®šåˆ†è¾¨ç‡
        """
    )
    
    parser.add_argument('--weights', '-w', type=str, default=None,
                        help='Path to pretrained weights (optional, uses random init if not provided)')
    parser.add_argument('--output', '-o', type=str, default='models/sgsnet.onnx',
                        help='Output ONNX file path (default: models/sgsnet.onnx)')
    parser.add_argument('--height', type=int, default=480,
                        help='Input image height (default: 480)')
    parser.add_argument('--width', type=int, default=640,
                        help='Input image width (default: 640)')
    parser.add_argument('--model-size', type=str, default='standard',
                        choices=['lite', 'standard', 'large'],
                        help='Model size: lite (~2MB), standard (~15MB), large (~50MB)')
    parser.add_argument('--max-depth', type=float, default=100.0,
                        help='Maximum depth value in meters (default: 100.0)')
    parser.add_argument('--opset', type=int, default=13,
                        help='ONNX opset version (default: 13)')
    
    args = parser.parse_args()
    
    success = export_onnx(
        weights_path=args.weights,
        output_path=args.output,
        height=args.height,
        width=args.width,
        model_size=args.model_size,
        max_depth=args.max_depth,
        opset_version=args.opset
    )
    
    sys.exit(0 if success else 1)


if __name__ == "__main__":
    main()